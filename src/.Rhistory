l <- tokens_lookup(test,
dictionary = dict2)
l
str(FEEL_fr)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
sum(lengths(dict))
sum(sapply(dict, nrow))
dict <- lapply(dict, function(x) select(x, -sentiment))
sum(sapply(dict, nrow))
head(dict$negative, 500)
head(dict$negative, 500) %>%  as.vector()
head(dict$negative, 500) %>% unlist
library(pbmcapply)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
set.seed(123)
dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict
dict <- lapply(dict, function(x) select(x, -sentiment))
dict <- dictionary(dict)
system.time(
l <- tokens_lookup(test,
dictionary = dict)
)
system.time(
l <- pbmclapply(unlist(test), function(x) tokens_lookup(tokens(x),
dictionary = dict), mc.cores =5)
)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+', x$word), ])
dict
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
dict
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+', x$word), ])
dict
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
dict$negative
dict <- lapply(dict, function(x) select(x, -sentiment))
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+|\\|', x$word), ])
dict <- lapply(dict, function(x) select(x, -sentiment))
head(dict$negative, 500) %>% unlist
sum(sapply(dict, nrow))
library(udpipe)
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/FEEL_fr.rda"))
str(FEEL_fr)
dict <- as_tibble(FEEL_fr) %>% rename(polarity = y, term = x)
dict
l <- txt_sentiment(test, polarity_terms = dict)
test <- tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même')
udpipe(test, "french-spoken", trace = 10)
test <- 'Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même'
udpipe(test, "french-spoken", trace = 10)
test <- udpipe(test, "french-spoken", trace = 10)
l <- txt_sentiment(test, polarity_terms = dict)
l
l
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/FEEL_fr.rda"))
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/valence-raw/valShifters.rda"))
polarity_terms <- rename(FEEL_fr, term = x, polarity = y)
polarity_negators <- subset(valShifters$valence_fr, t == 1)$x
polarity_amplifiers <- subset(valShifters$valence_fr, t == 2)$x
polarity_deamplifiers <- subset(valShifters$valence_fr, t == 3)$x
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(test, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments
polarity_negators
polarity_amplifiers
load("~/Downloads/NR_SR_Jan_Okt_2019.RData")
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
txt <- romandie_tweets2$Text
head(txt)
txt <- txt[sample(1:length(txt), 200)]
txt
romandie_tweets2 <- udpipe(txt, "french-spoken", trace = 10)
romandie_tweets2
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(txt, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(romandie_tweets2, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments
# Prepping the dict
romandie_udpipe <- udpipe(txt, "french-spoken", trace = 10)
sentiments
# graph
library(magrittr)
library(ggraph)
library(igraph)
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
sentiments
# sentiment
sentiments_txt <- txt_sentiment(romandie_udpipe, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments <- sentiments_txt$data
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
reasons <- filter(reasons, dep_rel %in% "amod")
word_cooccurences <- reasons %>%
group_by(lemma, lemma_parent) %>%
summarise(cooc = n()) %>%
arrange(-cooc)
vertices <- bind_rows(
data_frame(key = unique(reasons$lemma)) %>% mutate(in_dictionary = if_else(key %in% polarity_terms$term, "in_dictionary", "linked-to")),
data_frame(key = unique(setdiff(reasons$lemma_parent, reasons$lemma))) %>% mutate(in_dictionary = "linked-to"))
# graph
library(magrittr)
library(ggraph)
library(igraph)
cooc <- head(word_cooccurences, 20)
set.seed(123)
cooc %>%
graph_from_data_frame(vertices = filter(vertices, key %in% c(cooc$lemma, cooc$lemma_parent))) %>%
ggraph(layout = "fr") +
geom_edge_link0(aes(edge_alpha = cooc, edge_width = cooc)) +
geom_node_point(aes(colour = in_dictionary), size = 5) +
geom_node_text(aes(label = name), vjust = 1.8, col = "darkgreen") +
ggtitle("Which words are linked to the negative terms") +
theme_void()
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 200)]
head(romandie_txt)
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_tweets2$Text
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_tweets2
romandie_tweets2$Text
head(romandie_tweets2)
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
romandie_tweets2
romandie_tweets2
romandie_tweets2$Text
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 200)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_udpipe <- udpipe(romandie_txt, "french-spoken", trace = 10)  # only using a small sample first to figure out all the settings and not waste time
# sentiment
sentiments_txt <- txt_sentiment(romandie_udpipe, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments <- sentiments_txt$data
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
reasons <- filter(reasons, dep_rel %in% "amod")
word_cooccurences <- reasons %>%
group_by(lemma, lemma_parent) %>%
summarise(cooc = n()) %>%
arrange(-cooc)
vertices <- bind_rows(
data_frame(key = unique(reasons$lemma)) %>% mutate(in_dictionary = if_else(key %in% polarity_terms$term, "in_dictionary", "linked-to")),
data_frame(key = unique(setdiff(reasons$lemma_parent, reasons$lemma))) %>% mutate(in_dictionary = "linked-to"))
cooc <- head(word_cooccurences, 20)
set.seed(123)
cooc %>%
graph_from_data_frame(vertices = filter(vertices, key %in% c(cooc$lemma, cooc$lemma_parent))) %>%
ggraph(layout = "fr") +
geom_edge_link0(aes(edge_alpha = cooc, edge_width = cooc)) +
geom_node_point(aes(colour = in_dictionary), size = 5) +
geom_node_text(aes(label = name), vjust = 1.8, col = "darkgreen") +
ggtitle("Which words are linked to the negative terms") +
theme_void()
install.packages('qualtRics')
library(qualtRics)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.align = 'center')
filepath <- '/Users/lucienbaumgartner/Dropbox/thesis/embed.R/input/TC+Embeddings+Valence+Control_April+28,+2020_09.13.csv'
library(reticulate)
os <- import("os")
os$listdir(".")
Sys.which("python")
#spacy_install()
use_condaenv("myenv")
spacyr::spacy_initialize(condaenv = "myenv")
#spacy_install()
use_condaenv("myenv", required = T)
#spacy_install()
use_virtualenv("myenv")
spacyr::spacy_initialize(virtualenv =  = "myenv")
spacyr::spacy_initialize(virtualenv  = "myenv")
spacyr::spacy_initialize()
#spacy_install()
use_python("/Users/lucienbaumgartner/.conda/envs/spacy_condaenv/bin/python")
spacyr::spacy_initialize()
spacyr::spacy_initialize(python_executable = '/Users/lucienbaumgartner/.conda/envs/spacy_condaenv/bin/python')
library(sparklyr)
sc <- spark_connect(master = "local", version = "3.0")
options(sparklyr.java9 = TRUE)
sc <- spark_connect(master = "local", version = "3.0")
spark_disconnect(sc)
library(quanteda)
library(ggplot2)
library(dplyr)
library(purrr)
library(xtable)
library(envalysis)
library(gridExtra)
library(pbmcapply)
library(tm)
library(textstem)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
collection <- list()
load('../output/02-finalized-corpora/baseline/reddit/BC_consolidated_full_sentiment.RDS')
collection[[1]] <- p_spource
collection[[1]] <- p_source
load('../output/02-finalized-corpora/legal/LC_consolidated_full_sentiment.RDS')
collection[[2]] <- p_source
str(collection)
# means of mean
means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, mean)
means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, mean)
mean(unlist(means_lc_per_doc))
mean(unlist(means_bc_per_doc))
# means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(mList_lc)
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(mList_bc)
### ABSOLUTE MEANS (INTENSITY)
# means of means
abs_means_lc_per_doc <- lapply(abs(collection[[1]]$doc_sentiment), mean)
### ABSOLUTE MEANS (INTENSITY)
# means of means
abs_means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, function(x) mean(abs(x)))
abs_means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, function(x) mean(abs(x)))
mean(unlist(abs_means_lc_per_doc))
mean(unlist(abs_means_bc_per_doc))
e
# means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
qflbfb
nbcwehvh
### MEANS by POLARITY
# means of means
means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, mean)
means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, mean)
mean(unlist(means_lc_per_doc))
mean(unlist(means_bc_per_doc))
# means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(mList_lc)
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(mList_bc)
### ABSOLUTE MEANS (INTENSITY)
# means of means
abs_means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, function(x) mean(abs(x)))
abs_means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, function(x) mean(abs(x)))
mean(unlist(abs_means_lc_per_doc))
mean(unlist(abs_means_bc_per_doc))
# means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
## significance test
m1 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentimenr = unlist(means_bc_per_doc), corpus = 'bc'))
## significance test
m1 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(means_bc_per_doc), corpus = 'bc'))
m1 <- lm(sentiment ~ corpus, m1)
m1
summary(m1)
emmeans::emmeans(m1, by = 'corpus')
emmeans::emmeans(m1)
emmeans::emmeans(data = m1)
emmeans::emmeans(m1, specs = pairwise ~ corpus, at = list(.group = c("lc", "bc")))
m1
## significance test
data_m1 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(means_bc_per_doc), corpus = 'bc'))
m1 <- lm(sentiment ~ corpus, data = data_m1)
summary(m1)
emmeans(m1, specs = pairwise ~ corpus, at = list(.group = c("lc", "bc")))
library(emmeans)
emmeans(m1, specs = pairwise ~ corpus, at = list(.group = c("lc", "bc")))
emmeans(m1, specs = pairwise ~ corpus)
## significance test
data_m2 <- rbind(tibble(sentiment = mList_lc, corpus = 'lc'),
tibble(sentiment = mList_bc, corpus = 'bc'))
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(mList_lc)
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(mList_bc)
## significance test
data_m2 <- rbind(tibble(sentiment = mList_lc, corpus = 'lc'),
tibble(sentiment = mList_bc, corpus = 'bc'))
m2 <- lm(sentiment ~ corpus, data = data_m2)
emmeans(m2, specs = pairwise ~ corpus)
### ABSOLUTE MEANS (INTENSITY)
## means of means
abs_means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, function(x) mean(abs(x)))
abs_means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, function(x) mean(abs(x)))
mean(unlist(abs_means_lc_per_doc))
mean(unlist(abs_means_bc_per_doc))
## significance test
data_m3 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(means_bc_per_doc), corpus = 'bc'))
m3 <- lm(sentiment ~ corpus, data = data_m3)
emmeans(m3, specs = pairwise ~ corpus)
## significance test
data_m3 <- rbind(tibble(sentiment = unlist(abs_means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(abs_means_bc_per_doc), corpus = 'bc'))
m3 <- lm(sentiment ~ corpus, data = data_m3)
emmeans(m3, specs = pairwise ~ corpus)
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
## significance test
data_m4 <- rbind(tibble(sentiment = mList_lc, corpus = 'lc'),
tibble(sentiment = mList_bc, corpus = 'bc'))
m4 <- lm(sentiment ~ corpus, data = data_m4)
emmeans(m4, specs = pairwise ~ corpus)
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
## significance test
data_m4 <- rbind(tibble(sentiment = abs(mList_lc), corpus = 'lc'),
tibble(sentiment = abs(mList_bc), corpus = 'bc'))
m4 <- lm(sentiment ~ corpus, data = data_m4)
emmeans(m4, specs = pairwise ~ corpus)
eberhverv
hvherbvhe
ewnbvhebrvh
¨
### MEANS by POLARITY
## means of means
means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, mean)
means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, mean)
mean(unlist(means_lc_per_doc))
mean(unlist(means_bc_per_doc))
## significance test
data_m1 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(means_bc_per_doc), corpus = 'bc'))
m1 <- lm(sentiment ~ corpus, data = data_m1)
emmeans(m1, specs = pairwise ~ corpus)
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(mList_lc)
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(mList_bc)
## significance test
data_m2 <- rbind(tibble(sentiment = mList_lc, corpus = 'lc'),
tibble(sentiment = mList_bc, corpus = 'bc'))
m2 <- lm(sentiment ~ corpus, data = data_m2)
emmeans(m2, specs = pairwise ~ corpus)
### ABSOLUTE MEANS (INTENSITY)
## means of means
abs_means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, function(x) mean(abs(x)))
abs_means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, function(x) mean(abs(x)))
mean(unlist(abs_means_lc_per_doc))
mean(unlist(abs_means_bc_per_doc))
## significance test
data_m3 <- rbind(tibble(sentiment = unlist(abs_means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(abs_means_bc_per_doc), corpus = 'bc'))
m3 <- lm(sentiment ~ corpus, data = data_m3)
emmeans(m3, specs = pairwise ~ corpus)
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
## significance test
data_m4 <- rbind(tibble(sentiment = abs(mList_lc), corpus = 'lc'),
tibble(sentiment = abs(mList_bc), corpus = 'bc'))
m4 <- lm(sentiment ~ corpus, data = data_m4)
emmeans(m4, specs = pairwise ~ corpus)
# !diagnostics off
library(quanteda)
library(ggplot2)
library(dplyr)
library(emmeans)
library(xtable)
library(factoextra)
library(Ckmeans.1d.dp)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# function for linebreaks in plots
abbrv <- function(x, width = 200) lapply(strwrap(x, width, simplify = FALSE), paste, collapse="\n")
# load data
load('../output/02-finalized-corpora/legal/LC_consolidated.RDS')
# combine to full corpus
df <- df %>%
mutate(cat = dplyr::recode(cat, epistemic = 'Epistemic', legal = 'Legal', tc = 'TC', descriptive = 'Desc.'))
# differences between concept classes
m1 <- lm(abs(sentiWords) ~ cat, data = df)
emm1 <- emmeans(m1, specs = pairwise ~ cat)
emm1
res1 <- xtable(emm1$contrasts)
print(res1, include.rownames = F)
# same results in anova
m1a <- aov(abs(sentiWords) ~ cat, data = df)
emmeans(m1a, specs = pairwise ~ cat)
unique(df$cat)
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
m2 <- lm(sentiWords ~ cat*TARGET_pol_new, data = df[!df$cat=="Desc."])
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
m2 <- lm(sentiWords ~ cat*TARGET_pol_new, data = df[!df$cat=="Desc.",])
unique(df$TARGET_pol_new)
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
m2 <- lm(sentiWords ~ cat*TARGET_pol_new, data = df[!df$cat=="Desc.",])
emm2 <- emmeans(m2, specs = pairwise ~ cat, by ='TARGET_pol_new')
res2 <- xtable(emm2$contrasts)
print(res1, include.rownames = F)
print(res2, include.rownames = F)
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
df[!df$cat=="Desc.",] %>%
group_by(TARGET) %>%
summary(mean(sentiWords))
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
df[!df$cat=="Desc.",] %>%
group_by(TARGET) %>%
summarise(mean(sentiWords))
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
df[df$cat=="Desc.",] %>%
group_by(TARGET) %>%
summarise(mean(sentiWords))
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
df[df$cat=="Desc.",] %>%
group_by(TARGET) %>%
summarise(mean(sentiWords))
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
vec <- df[df$cat=="Desc.",] %>%
group_by(TARGET) %>%
summarise(mean(sentiWords))
# differences between concept classes incl target polarity (NOTE: without descriptive concepts)
vec <- df[df$cat=="Desc.",] %>%
group_by(TARGET) %>%
summarise(avg = mean(sentiWords))
dfx <- df %>%
mutate(
TARGET_pol_new_recoded = case_when(
TARGET %in% vec$TARGET[vec$avg > 0] ~ 'positive',
TARGET %in% vec$TARGET[vec$avg < 0] ~ 'negative',
TRUE ~ TARGET_pol_new
)
)
m2 <- lm(sentiWords ~ cat*TARGET_pol_new_recoded, data = dfx)
emm2 <- emmeans(m2, specs = pairwise ~ cat, by ='TARGET_pol_new_recoded')
m3 <- lm(sentiWords ~ cat*TARGET_pol_new_recoded, data = dfx)
emm3 <- emmeans(m3, specs = pairwise ~ cat, by ='TARGET_pol_new_recoded')
res3 <- xtable(emm3$contrasts)
print(res3, include.rownames = F)
