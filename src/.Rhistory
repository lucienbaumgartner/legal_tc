dta <- df$txt %>% trimws %>% gsub('^.*(?=(rude\\sand))', '', ., perl = T)
dta <- udpipe_annotate(udmodel, dta)
dta <- as.data.frame(dta) %>% as_tibble
dta <- split(dta, dta$doc_id)
snippetize <- function(x){
if(all(x$upos[1:3]==c('ADJ', 'CCONJ', 'ADJ'))){
return(paste0(x$token[1:3], collapse = ' '))
}
if(FALSE){
}
#else if(any(x$upos[3:6]%in%c('ADJ', 'NOUN'))){
#  return(x$token[1:grep('ADJ|NOUN', x$upos)[2]])
#}
else{
return(NULL)
}
}
p <- lapply(dta, snippetize)
p <- tibble(snippet=unlist(p), docid=names(p)[!sapply(p, is.null)])
lp <- as.list(tokens_lookup(tokens(trimws(gsub('rude\\sand', '', p$snippet))), dictionary = data_dictionary_LSD2015))
lp[sapply(lp, function(x) identical(x, character(0)))] <- 'no sentiment available'
lp
lp <- unlist(lp)
p <- cbind(p, lp)
p
p <- lapply(dta, snippetize)
p <- tibble(snippet=unlist(p), docid=names(p)[!sapply(p, is.null)])
lp <- as.list(tokens_lookup(tokens(trimws(gsub('rude\\sand', '', p$snippet))), dictionary = data_dictionary_LSD2015))
lp[sapply(lp, function(x) identical(x, character(0)))] <- 'no sentiment available'
lp <- unlist(lp)
p <- cbind(p, sentiment=lp)
p
fin <- left_join(p, df, by='docid')
write.csv(fin,'~/Dropbox/thesis/scripts/test_annot.csv', row.names = F)
fin %>% filter(sentiment=='positive')
fin
table(p$sentiment)
table(p$sentiment)/nrow(p)
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/FEEL_fr.rda"))
str(FEEL_fr)
table(FEEL_fr$y, useNA = 'always')
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
library(dplyr)
table(FEEL_fr$y, useNA = 'always')
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
dict <- lapply(dict, function(x) select(x, -sentiment))
dict
dict <- dictionary(dict)
###########################################################
# Setup
library(tidyverse)
library(quanteda)
dict <- dictionary(dict)
tokens_lookup('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même',
dictionary = dict, valuetype = "glob")
tokens_lookup(tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même'),
dictionary = dict, valuetype = "glob")
test <- tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même')
test
str(dict)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict
dict <- split(dict, dict$sentiment)
dict <- lapply(dict, function(x) select(x, -sentiment))
dict
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict
dict <- dictionary(dict)
dict <- split(dict, dict$sentiment)
dict <- lapply(dict, function(x) select(x, -sentiment))
dict <- dictionary(dict)
test <- tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même')
str(dict)
l <- tokens_lookup(test,
dictionary = dict)
list(positive = c('Révolution', 'comme', 'apéro', 'grève', 'monsieur', 'omelette'),
negative = c('Dire', 'et'))
p <- list(positive = c('Révolution', 'comme', 'apéro', 'grève', 'monsieur', 'omelette'),
negative = c('Dire', 'et'))
dict2 <- dictionary(p)
dict2
l <- tokens_lookup(test,
dictionary = dict2)
l
p
dict2 <- dictionary(p)
dict2
l <- tokens_lookup(test,
dictionary = dict2)
l
str(FEEL_fr)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
sum(lengths(dict))
sum(sapply(dict, nrow))
dict <- lapply(dict, function(x) select(x, -sentiment))
sum(sapply(dict, nrow))
head(dict$negative, 500)
head(dict$negative, 500) %>%  as.vector()
head(dict$negative, 500) %>% unlist
library(pbmcapply)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
set.seed(123)
dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict
dict <- lapply(dict, function(x) select(x, -sentiment))
dict <- dictionary(dict)
system.time(
l <- tokens_lookup(test,
dictionary = dict)
)
system.time(
l <- pbmclapply(unlist(test), function(x) tokens_lookup(tokens(x),
dictionary = dict), mc.cores =5)
)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+', x$word), ])
dict
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
dict
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+', x$word), ])
dict
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
dict$negative
dict <- lapply(dict, function(x) select(x, -sentiment))
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+|\\|', x$word), ])
dict <- lapply(dict, function(x) select(x, -sentiment))
head(dict$negative, 500) %>% unlist
sum(sapply(dict, nrow))
library(udpipe)
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/FEEL_fr.rda"))
str(FEEL_fr)
dict <- as_tibble(FEEL_fr) %>% rename(polarity = y, term = x)
dict
l <- txt_sentiment(test, polarity_terms = dict)
test <- tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même')
udpipe(test, "french-spoken", trace = 10)
test <- 'Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même'
udpipe(test, "french-spoken", trace = 10)
test <- udpipe(test, "french-spoken", trace = 10)
l <- txt_sentiment(test, polarity_terms = dict)
l
l
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/FEEL_fr.rda"))
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/valence-raw/valShifters.rda"))
polarity_terms <- rename(FEEL_fr, term = x, polarity = y)
polarity_negators <- subset(valShifters$valence_fr, t == 1)$x
polarity_amplifiers <- subset(valShifters$valence_fr, t == 2)$x
polarity_deamplifiers <- subset(valShifters$valence_fr, t == 3)$x
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(test, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments
polarity_negators
polarity_amplifiers
load("~/Downloads/NR_SR_Jan_Okt_2019.RData")
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
txt <- romandie_tweets2$Text
head(txt)
txt <- txt[sample(1:length(txt), 200)]
txt
romandie_tweets2 <- udpipe(txt, "french-spoken", trace = 10)
romandie_tweets2
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(txt, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(romandie_tweets2, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments
# Prepping the dict
romandie_udpipe <- udpipe(txt, "french-spoken", trace = 10)
sentiments
# graph
library(magrittr)
library(ggraph)
library(igraph)
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
sentiments
# sentiment
sentiments_txt <- txt_sentiment(romandie_udpipe, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments <- sentiments_txt$data
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
reasons <- filter(reasons, dep_rel %in% "amod")
word_cooccurences <- reasons %>%
group_by(lemma, lemma_parent) %>%
summarise(cooc = n()) %>%
arrange(-cooc)
vertices <- bind_rows(
data_frame(key = unique(reasons$lemma)) %>% mutate(in_dictionary = if_else(key %in% polarity_terms$term, "in_dictionary", "linked-to")),
data_frame(key = unique(setdiff(reasons$lemma_parent, reasons$lemma))) %>% mutate(in_dictionary = "linked-to"))
# graph
library(magrittr)
library(ggraph)
library(igraph)
cooc <- head(word_cooccurences, 20)
set.seed(123)
cooc %>%
graph_from_data_frame(vertices = filter(vertices, key %in% c(cooc$lemma, cooc$lemma_parent))) %>%
ggraph(layout = "fr") +
geom_edge_link0(aes(edge_alpha = cooc, edge_width = cooc)) +
geom_node_point(aes(colour = in_dictionary), size = 5) +
geom_node_text(aes(label = name), vjust = 1.8, col = "darkgreen") +
ggtitle("Which words are linked to the negative terms") +
theme_void()
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 200)]
head(romandie_txt)
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_tweets2$Text
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_tweets2
romandie_tweets2$Text
head(romandie_tweets2)
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
romandie_tweets2
romandie_tweets2
romandie_tweets2$Text
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 200)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_udpipe <- udpipe(romandie_txt, "french-spoken", trace = 10)  # only using a small sample first to figure out all the settings and not waste time
# sentiment
sentiments_txt <- txt_sentiment(romandie_udpipe, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments <- sentiments_txt$data
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
reasons <- filter(reasons, dep_rel %in% "amod")
word_cooccurences <- reasons %>%
group_by(lemma, lemma_parent) %>%
summarise(cooc = n()) %>%
arrange(-cooc)
vertices <- bind_rows(
data_frame(key = unique(reasons$lemma)) %>% mutate(in_dictionary = if_else(key %in% polarity_terms$term, "in_dictionary", "linked-to")),
data_frame(key = unique(setdiff(reasons$lemma_parent, reasons$lemma))) %>% mutate(in_dictionary = "linked-to"))
cooc <- head(word_cooccurences, 20)
set.seed(123)
cooc %>%
graph_from_data_frame(vertices = filter(vertices, key %in% c(cooc$lemma, cooc$lemma_parent))) %>%
ggraph(layout = "fr") +
geom_edge_link0(aes(edge_alpha = cooc, edge_width = cooc)) +
geom_node_point(aes(colour = in_dictionary), size = 5) +
geom_node_text(aes(label = name), vjust = 1.8, col = "darkgreen") +
ggtitle("Which words are linked to the negative terms") +
theme_void()
install.packages('qualtRics')
library(qualtRics)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.align = 'center')
filepath <- '/Users/lucienbaumgartner/Dropbox/thesis/embed.R/input/TC+Embeddings+Valence+Control_April+28,+2020_09.13.csv'
library(reticulate)
os <- import("os")
os$listdir(".")
Sys.which("python")
#spacy_install()
use_condaenv("myenv")
spacyr::spacy_initialize(condaenv = "myenv")
#spacy_install()
use_condaenv("myenv", required = T)
#spacy_install()
use_virtualenv("myenv")
spacyr::spacy_initialize(virtualenv =  = "myenv")
spacyr::spacy_initialize(virtualenv  = "myenv")
spacyr::spacy_initialize()
#spacy_install()
use_python("/Users/lucienbaumgartner/.conda/envs/spacy_condaenv/bin/python")
spacyr::spacy_initialize()
spacyr::spacy_initialize(python_executable = '/Users/lucienbaumgartner/.conda/envs/spacy_condaenv/bin/python')
library(sparklyr)
sc <- spark_connect(master = "local", version = "3.0")
options(sparklyr.java9 = TRUE)
sc <- spark_connect(master = "local", version = "3.0")
spark_disconnect(sc)
# !diagnostics off
library(quanteda)
library(ggplot2)
library(dplyr)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# function for linebreaks in plots
abbrv <- function(x, width = 200) lapply(strwrap(x, width, simplify = FALSE), paste, collapse="\n")
# load data
load('../output/02-finalized-corpora/baseline/reddit/BC_consolidated.RDS')
bc <- df
load('../output/02-finalized-corpora/legal/LC_consolidated.RDS')
lc <- df
rm(df)
# combine to full corpus
df <- rbind(bc, select(lc, -id, -year, -court)) %>%
mutate(cat = dplyr::recode(cat, epistemic = 'Epistemic', legal = 'Legal', tc = 'TC'),
context = dplyr::recode(context, court = 'LC', reddit = 'BC'))
# create group variable
df <- mutate(df, group = paste0(cat, TARGET_pol, collapse = '_'))
### H1
m1 <- lm(abs(sentiWords) ~ context, data = dfx)
anova(m1)
### H1
m1 <- lm(abs(sentiWords) ~ context, data = df)
anova(m1)
emm1 <-  emmeans(m1, specs = pairwise ~ context, at = list(.group = c("reddit", "legal")))
library(emmeans)
emm1 <-  emmeans(m1, specs = pairwise ~ context, at = list(.group = c("reddit", "legal")))
emm1 <-  emmeans(m1, specs = pairwise ~ context, at = list(.group = c("BC", "LC")))
emm1
emm1 <- pwpp(emm1$emmeans, method = "trt.vs.ctrl1", type = "response", side = ">")
emm1
### H1a & H1b
m2 <- lm(sentiWords ~ context * TARGET_pol, data = df)
anova(m2)
emm2 <- emmeans(m2, specs = pairwise ~ context, at = list(.group = c("reddit", "legal")), by = 'TARGET_pol')
emm2 <- emmeans(m2, specs = pairwise ~ context, at = list(.group = c("BC", "LC")), by = 'TARGET_pol')
emm2
# filter out descriptive target adjectives for study 1
df <- filter(df, TARGET_pol == 'neutral')
### H1
m1 <- lm(abs(sentiWords) ~ context, data = df)
df
### H1
m1 <- lm(abs(sentiWords) ~ context, data = df)
# combine to full corpus
df <- rbind(bc, select(lc, -id, -year, -court)) %>%
mutate(cat = dplyr::recode(cat, epistemic = 'Epistemic', legal = 'Legal', tc = 'TC'),
context = dplyr::recode(context, court = 'LC', reddit = 'BC'))
# filter out descriptive target adjectives for study 1
df <- filter(df, !TARGET_pol == 'neutral')
### H1
m1 <- lm(abs(sentiWords) ~ context, data = df)
anova(m1)
emm1 <-  emmeans(m1, specs = pairwise ~ context, at = list(.group = c("BC", "LC")))
emm1
# write out results
xtable(emm1$emmeans)
library(xtable)
emm1
# write out results
xtable(emm1$emmeans)
# write out results
print(xtable(emm1$emmeans), include.rownames = F, file = '../output/03-results/tables/study1_h1.tex')
# write out results
res1 <- xtable(emm1$emmeans)
print(res1, include.rownames = F, file = '../output/03-results/tables/study1_h1.tex')
print(res1, file = '../output/03-results/tables/study1_h1.tex', include.rownames = F)
print(res1, file = '../output/03-results/tables/summary_stats.tex', include.rownames = F)
### H1a & H1b
m2 <- lm(sentiWords ~ context * TARGET_pol, data = df)
anova(m2)
emm2 <- emmeans(m2, specs = pairwise ~ context, at = list(.group = c("BC", "LC")), by = 'TARGET_pol')
emm2
# write out results
res1 <- xtable(emm2$emmeans)
print(res1, file = '../output/03-results/tables/summary_stats.tex', include.rownames = F)
### H2a & H2b
m3 <- lm(abs(sentiWords) ~ context * cat, data = df)
emm3 <- emmeans(m3, specs = pairwise ~ cat, at = list(.group = c("reddit", "legal")), by = 'context')
emm3
emm3 <- emmeans(m3, specs = pairwise ~ cat, at = list(.group = c("BC", "LC")), by = 'context')
### H2a & H2b
m3 <- lm(abs(sentiWords) ~ context * cat, data = df)
emm3 <- emmeans(m3, specs = pairwise ~ cat, at = list(.group = c("BC", "LC")), by = 'context')
emm3
res1 <- xtable(emm2$contrasts)
res2 <- xtable(emm2$contrasts)
print(res2, include.rownames = F)
res2 <- xtable(emm3$contrasts)
res3 <- xtable(emm3$contrasts)
print(res3, include.rownames = F)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# function for linebreaks in plots
abbrv <- function(x, width = 200) lapply(strwrap(x, width, simplify = FALSE), paste, collapse="\n")
# load data
load('../output/02-finalized-corpora/legal/LC_consolidated.RDS')
# combine to full corpus
df <- lc %>%
mutate(cat = dplyr::recode(cat, epistemic = 'Epistemic', legal = 'Legal', tc = 'TC', descriptive = 'Desc.'))
# combine to full corpus
df <- df %>%
mutate(cat = dplyr::recode(cat, epistemic = 'Epistemic', legal = 'Legal', tc = 'TC', descriptive = 'Desc.'))
df
# differences between concept classes
m1 <- lm(abs(sentiWords) ~ cat, data = df)
emm2 <- emmeans(m2, specs = pairwise ~ cat))
emm2 <- emmeans(m2, specs = pairwise ~ cat)
emm2 <- emmeans(m1, specs = pairwise ~ cat)
emm2
res1 <- xtable(emm2)
res1 <- xtable(emm2$contrasts)
# differences between concept classes
m1 <- lm(abs(sentiWords) ~ cat, data = df)
emm1 <- emmeans(m1, specs = pairwise ~ cat)
res1 <- xtable(emm1$contrasts)
print(res1, include.rownames = F¨)
print(res1, include.rownames = F)
# !diagnostics off
library(quanteda)
library(ggplot2)
library(dplyr)
library(emmeans)
library(xtable)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# function for linebreaks in plots
abbrv <- function(x, width = 200) lapply(strwrap(x, width, simplify = FALSE), paste, collapse="\n")
# load data
load('../output/02-finalized-corpora/baseline/reddit/BC_consolidated.RDS')
bc <- df
load('../output/02-finalized-corpora/legal/LC_consolidated.RDS')
lc <- df
rm(df)
# combine to full corpus
df <- rbind(bc, select(lc, -id, -year, -court)) %>%
mutate(cat = dplyr::recode(cat, epistemic = 'Epistemic', legal = 'Legal', tc = 'TC'),
context = dplyr::recode(context, court = 'LC', reddit = 'BC'))
# filter out descriptive target adjectives for study 1
df <- filter(df, !TARGET_pol == 'neutral')
# create group variable
df <- mutate(df, group = paste0(cat, TARGET_pol, collapse = '_'))
### H1
m1 <- lm(abs(sentiWords) ~ context, data = df)
m1
summary(m1)
anova(m1)
### H1a & H1b
m2 <- lm(sentiWords ~ context * TARGET_pol, data = df)
anova(m2)
emm2 <- emmeans(m2, specs = pairwise ~ context, at = list(.group = c("BC", "LC")), by = 'TARGET_pol')
emm2
summary(m2)
emm3 <- emmeans(m3, specs = pairwise ~ cat, by = 'cat')
### H2a & H2b
m3 <- lm(abs(sentiWords) ~ context * cat, data = df)
emm3 <- emmeans(m3, specs = pairwise ~ cat, by = 'cat')
emm3
df
emm3 <- emmeans(m3, specs = pairwise ~ cat, at = list(.group = c("Epistemic", "TC", "Legal")), by = 'cat')
emm3
emm3 <- emmeans(m3, specs = pairwise ~ context, at = list(.group = c("Epistemic", "TC", "Legal")), by = 'cat')
emm3
res3 <- xtable(emm3$contrasts)
print(res3, include.rownames = F)
summary(m3)
xtable(summary(m3))
library(stargazer)
stargazer(summary(m3))
stargazer(m3)
