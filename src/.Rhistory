#}
else{
return(NULL)
}
}
p <- lapply(dta, snippetize)
p <- tibble(snippet=unlist(p), docid=names(p)[!sapply(p, is.null)])
lp <- as.list(tokens_lookup(tokens(trimws(gsub('rude\\sand', '', p$snippet))), dictionary = data_dictionary_LSD2015))
lp[sapply(lp, function(x) identical(x, character(0)))] <- 'no sentiment available'
lp
lp <- unlist(lp)
p <- cbind(p, lp)
p
p <- lapply(dta, snippetize)
p <- tibble(snippet=unlist(p), docid=names(p)[!sapply(p, is.null)])
lp <- as.list(tokens_lookup(tokens(trimws(gsub('rude\\sand', '', p$snippet))), dictionary = data_dictionary_LSD2015))
lp[sapply(lp, function(x) identical(x, character(0)))] <- 'no sentiment available'
lp <- unlist(lp)
p <- cbind(p, sentiment=lp)
p
fin <- left_join(p, df, by='docid')
write.csv(fin,'~/Dropbox/thesis/scripts/test_annot.csv', row.names = F)
fin %>% filter(sentiment=='positive')
fin
table(p$sentiment)
table(p$sentiment)/nrow(p)
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/FEEL_fr.rda"))
str(FEEL_fr)
table(FEEL_fr$y, useNA = 'always')
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
library(dplyr)
table(FEEL_fr$y, useNA = 'always')
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
dict <- lapply(dict, function(x) select(x, -sentiment))
dict
dict <- dictionary(dict)
###########################################################
# Setup
library(tidyverse)
library(quanteda)
dict <- dictionary(dict)
tokens_lookup('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même',
dictionary = dict, valuetype = "glob")
tokens_lookup(tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même'),
dictionary = dict, valuetype = "glob")
test <- tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même')
test
str(dict)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict
dict <- split(dict, dict$sentiment)
dict <- lapply(dict, function(x) select(x, -sentiment))
dict
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict
dict <- dictionary(dict)
dict <- split(dict, dict$sentiment)
dict <- lapply(dict, function(x) select(x, -sentiment))
dict <- dictionary(dict)
test <- tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même')
str(dict)
l <- tokens_lookup(test,
dictionary = dict)
list(positive = c('Révolution', 'comme', 'apéro', 'grève', 'monsieur', 'omelette'),
negative = c('Dire', 'et'))
p <- list(positive = c('Révolution', 'comme', 'apéro', 'grève', 'monsieur', 'omelette'),
negative = c('Dire', 'et'))
dict2 <- dictionary(p)
dict2
l <- tokens_lookup(test,
dictionary = dict2)
l
p
dict2 <- dictionary(p)
dict2
l <- tokens_lookup(test,
dictionary = dict2)
l
str(FEEL_fr)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
sum(lengths(dict))
sum(sapply(dict, nrow))
dict <- lapply(dict, function(x) select(x, -sentiment))
sum(sapply(dict, nrow))
head(dict$negative, 500)
head(dict$negative, 500) %>%  as.vector()
head(dict$negative, 500) %>% unlist
library(pbmcapply)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
set.seed(123)
dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict
dict <- lapply(dict, function(x) select(x, -sentiment))
dict <- dictionary(dict)
system.time(
l <- tokens_lookup(test,
dictionary = dict)
)
system.time(
l <- pbmclapply(unlist(test), function(x) tokens_lookup(tokens(x),
dictionary = dict), mc.cores =5)
)
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+', x$word), ])
dict
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
dict
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+', x$word), ])
dict
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
dict$negative
dict <- lapply(dict, function(x) select(x, -sentiment))
head(dict$negative, 500) %>% unlist
dict <- as_tibble(FEEL_fr) %>% mutate(sentiment = ifelse(y==-1, 'negative', 'positive')) %>% rename(word = x) %>% select(-y)
dict <- split(dict, dict$sentiment)
#dict <- lapply(dict, function(x) x[sample(1:nrow(x), 200), ])
dict <- lapply(dict, function(x) x[!grepl('\\s+|\\|', x$word), ])
dict <- lapply(dict, function(x) select(x, -sentiment))
head(dict$negative, 500) %>% unlist
sum(sapply(dict, nrow))
library(udpipe)
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/FEEL_fr.rda"))
str(FEEL_fr)
dict <- as_tibble(FEEL_fr) %>% rename(polarity = y, term = x)
dict
l <- txt_sentiment(test, polarity_terms = dict)
test <- tokens('Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même')
udpipe(test, "french-spoken", trace = 10)
test <- 'Révolution comme apéro grève monsieur omelette. Dire et paf le chien carrément putain merde frenchtech. Baguette boulangerie voir putain notre évidemment. Part révolution épicé car dans comme même'
udpipe(test, "french-spoken", trace = 10)
test <- udpipe(test, "french-spoken", trace = 10)
l <- txt_sentiment(test, polarity_terms = dict)
l
l
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/FEEL_fr.rda"))
load(file("https://github.com/sborms/sentometrics/raw/master/data-raw/valence-raw/valShifters.rda"))
polarity_terms <- rename(FEEL_fr, term = x, polarity = y)
polarity_negators <- subset(valShifters$valence_fr, t == 1)$x
polarity_amplifiers <- subset(valShifters$valence_fr, t == 2)$x
polarity_deamplifiers <- subset(valShifters$valence_fr, t == 3)$x
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(test, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments
polarity_negators
polarity_amplifiers
load("~/Downloads/NR_SR_Jan_Okt_2019.RData")
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
txt <- romandie_tweets2$Text
head(txt)
txt <- txt[sample(1:length(txt), 200)]
txt
romandie_tweets2 <- udpipe(txt, "french-spoken", trace = 10)
romandie_tweets2
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(txt, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
##
## Do sentiment analysis based on that open French lexicon
##
sentiments <- txt_sentiment(romandie_tweets2, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments
# Prepping the dict
romandie_udpipe <- udpipe(txt, "french-spoken", trace = 10)
sentiments
# graph
library(magrittr)
library(ggraph)
library(igraph)
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
sentiments
# sentiment
sentiments_txt <- txt_sentiment(romandie_udpipe, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments <- sentiments_txt$data
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
reasons <- filter(reasons, dep_rel %in% "amod")
word_cooccurences <- reasons %>%
group_by(lemma, lemma_parent) %>%
summarise(cooc = n()) %>%
arrange(-cooc)
vertices <- bind_rows(
data_frame(key = unique(reasons$lemma)) %>% mutate(in_dictionary = if_else(key %in% polarity_terms$term, "in_dictionary", "linked-to")),
data_frame(key = unique(setdiff(reasons$lemma_parent, reasons$lemma))) %>% mutate(in_dictionary = "linked-to"))
# graph
library(magrittr)
library(ggraph)
library(igraph)
cooc <- head(word_cooccurences, 20)
set.seed(123)
cooc %>%
graph_from_data_frame(vertices = filter(vertices, key %in% c(cooc$lemma, cooc$lemma_parent))) %>%
ggraph(layout = "fr") +
geom_edge_link0(aes(edge_alpha = cooc, edge_width = cooc)) +
geom_node_point(aes(colour = in_dictionary), size = 5) +
geom_node_text(aes(label = name), vjust = 1.8, col = "darkgreen") +
ggtitle("Which words are linked to the negative terms") +
theme_void()
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 200)]
head(romandie_txt)
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_tweets2$Text
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_tweets2
romandie_tweets2$Text
head(romandie_tweets2)
romandie_tweets2 <- subset(NR_SR_Jan_Okt_2019, Lang == "fr")
romandie_tweets2
romandie_tweets2
romandie_tweets2$Text
romandie_txt <- romandie_tweets2$Text
head(romandie_txt)
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 200)]
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_txt
romandie_txt <- romandie_tweets2$Text
romandie_txt <- romandie_txt[sample(1:length(romandie_txt), 500)]
romandie_udpipe <- udpipe(romandie_txt, "french-spoken", trace = 10)  # only using a small sample first to figure out all the settings and not waste time
# sentiment
sentiments_txt <- txt_sentiment(romandie_udpipe, term = "lemma",
polarity_terms = polarity_terms,
polarity_negators = polarity_negators,
polarity_amplifiers = polarity_amplifiers,
polarity_deamplifiers = polarity_deamplifiers)
sentiments <- sentiments_txt$data
reasons <- sentiments %>%
cbind_dependencies() %>%
select(doc_id, lemma, token, upos, sentiment_polarity, token_parent, lemma_parent, upos_parent, dep_rel) %>%
filter(sentiment_polarity < 0)
reasons <- filter(reasons, dep_rel %in% "amod")
word_cooccurences <- reasons %>%
group_by(lemma, lemma_parent) %>%
summarise(cooc = n()) %>%
arrange(-cooc)
vertices <- bind_rows(
data_frame(key = unique(reasons$lemma)) %>% mutate(in_dictionary = if_else(key %in% polarity_terms$term, "in_dictionary", "linked-to")),
data_frame(key = unique(setdiff(reasons$lemma_parent, reasons$lemma))) %>% mutate(in_dictionary = "linked-to"))
cooc <- head(word_cooccurences, 20)
set.seed(123)
cooc %>%
graph_from_data_frame(vertices = filter(vertices, key %in% c(cooc$lemma, cooc$lemma_parent))) %>%
ggraph(layout = "fr") +
geom_edge_link0(aes(edge_alpha = cooc, edge_width = cooc)) +
geom_node_point(aes(colour = in_dictionary), size = 5) +
geom_node_text(aes(label = name), vjust = 1.8, col = "darkgreen") +
ggtitle("Which words are linked to the negative terms") +
theme_void()
install.packages('qualtRics')
library(qualtRics)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.align = 'center')
filepath <- '/Users/lucienbaumgartner/Dropbox/thesis/embed.R/input/TC+Embeddings+Valence+Control_April+28,+2020_09.13.csv'
library(reticulate)
os <- import("os")
os$listdir(".")
Sys.which("python")
#spacy_install()
use_condaenv("myenv")
spacyr::spacy_initialize(condaenv = "myenv")
#spacy_install()
use_condaenv("myenv", required = T)
#spacy_install()
use_virtualenv("myenv")
spacyr::spacy_initialize(virtualenv =  = "myenv")
spacyr::spacy_initialize(virtualenv  = "myenv")
spacyr::spacy_initialize()
#spacy_install()
use_python("/Users/lucienbaumgartner/.conda/envs/spacy_condaenv/bin/python")
spacyr::spacy_initialize()
spacyr::spacy_initialize(python_executable = '/Users/lucienbaumgartner/.conda/envs/spacy_condaenv/bin/python')
library(sparklyr)
sc <- spark_connect(master = "local", version = "3.0")
options(sparklyr.java9 = TRUE)
sc <- spark_connect(master = "local", version = "3.0")
spark_disconnect(sc)
library(quanteda)
library(ggplot2)
library(dplyr)
library(purrr)
library(xtable)
library(envalysis)
library(gridExtra)
library(pbmcapply)
library(tm)
library(textstem)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
collection <- list()
load('../output/02-finalized-corpora/baseline/reddit/BC_consolidated_full_sentiment.RDS')
collection[[1]] <- p_spource
collection[[1]] <- p_source
load('../output/02-finalized-corpora/legal/LC_consolidated_full_sentiment.RDS')
collection[[2]] <- p_source
str(collection)
# means of mean
means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, mean)
means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, mean)
mean(unlist(means_lc_per_doc))
mean(unlist(means_bc_per_doc))
# means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(mList_lc)
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(mList_bc)
### ABSOLUTE MEANS (INTENSITY)
# means of means
abs_means_lc_per_doc <- lapply(abs(collection[[1]]$doc_sentiment), mean)
### ABSOLUTE MEANS (INTENSITY)
# means of means
abs_means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, function(x) mean(abs(x)))
abs_means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, function(x) mean(abs(x)))
mean(unlist(abs_means_lc_per_doc))
mean(unlist(abs_means_bc_per_doc))
e
# means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
qflbfb
nbcwehvh
### MEANS by POLARITY
# means of means
means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, mean)
means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, mean)
mean(unlist(means_lc_per_doc))
mean(unlist(means_bc_per_doc))
# means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(mList_lc)
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(mList_bc)
### ABSOLUTE MEANS (INTENSITY)
# means of means
abs_means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, function(x) mean(abs(x)))
abs_means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, function(x) mean(abs(x)))
mean(unlist(abs_means_lc_per_doc))
mean(unlist(abs_means_bc_per_doc))
# means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
## significance test
m1 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentimenr = unlist(means_bc_per_doc), corpus = 'bc'))
## significance test
m1 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(means_bc_per_doc), corpus = 'bc'))
m1 <- lm(sentiment ~ corpus, m1)
m1
summary(m1)
emmeans::emmeans(m1, by = 'corpus')
emmeans::emmeans(m1)
emmeans::emmeans(data = m1)
emmeans::emmeans(m1, specs = pairwise ~ corpus, at = list(.group = c("lc", "bc")))
m1
## significance test
data_m1 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(means_bc_per_doc), corpus = 'bc'))
m1 <- lm(sentiment ~ corpus, data = data_m1)
summary(m1)
emmeans(m1, specs = pairwise ~ corpus, at = list(.group = c("lc", "bc")))
library(emmeans)
emmeans(m1, specs = pairwise ~ corpus, at = list(.group = c("lc", "bc")))
emmeans(m1, specs = pairwise ~ corpus)
## significance test
data_m2 <- rbind(tibble(sentiment = mList_lc, corpus = 'lc'),
tibble(sentiment = mList_bc, corpus = 'bc'))
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(mList_lc)
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(mList_bc)
## significance test
data_m2 <- rbind(tibble(sentiment = mList_lc, corpus = 'lc'),
tibble(sentiment = mList_bc, corpus = 'bc'))
m2 <- lm(sentiment ~ corpus, data = data_m2)
emmeans(m2, specs = pairwise ~ corpus)
### ABSOLUTE MEANS (INTENSITY)
## means of means
abs_means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, function(x) mean(abs(x)))
abs_means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, function(x) mean(abs(x)))
mean(unlist(abs_means_lc_per_doc))
mean(unlist(abs_means_bc_per_doc))
## significance test
data_m3 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(means_bc_per_doc), corpus = 'bc'))
m3 <- lm(sentiment ~ corpus, data = data_m3)
emmeans(m3, specs = pairwise ~ corpus)
## significance test
data_m3 <- rbind(tibble(sentiment = unlist(abs_means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(abs_means_bc_per_doc), corpus = 'bc'))
m3 <- lm(sentiment ~ corpus, data = data_m3)
emmeans(m3, specs = pairwise ~ corpus)
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
## significance test
data_m4 <- rbind(tibble(sentiment = mList_lc, corpus = 'lc'),
tibble(sentiment = mList_bc, corpus = 'bc'))
m4 <- lm(sentiment ~ corpus, data = data_m4)
emmeans(m4, specs = pairwise ~ corpus)
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
## significance test
data_m4 <- rbind(tibble(sentiment = abs(mList_lc), corpus = 'lc'),
tibble(sentiment = abs(mList_bc), corpus = 'bc'))
m4 <- lm(sentiment ~ corpus, data = data_m4)
emmeans(m4, specs = pairwise ~ corpus)
eberhverv
hvherbvhe
ewnbvhebrvh
¨
### MEANS by POLARITY
## means of means
means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, mean)
means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, mean)
mean(unlist(means_lc_per_doc))
mean(unlist(means_bc_per_doc))
## significance test
data_m1 <- rbind(tibble(sentiment = unlist(means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(means_bc_per_doc), corpus = 'bc'))
m1 <- lm(sentiment ~ corpus, data = data_m1)
emmeans(m1, specs = pairwise ~ corpus)
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(mList_lc)
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(mList_bc)
## significance test
data_m2 <- rbind(tibble(sentiment = mList_lc, corpus = 'lc'),
tibble(sentiment = mList_bc, corpus = 'bc'))
m2 <- lm(sentiment ~ corpus, data = data_m2)
emmeans(m2, specs = pairwise ~ corpus)
### ABSOLUTE MEANS (INTENSITY)
## means of means
abs_means_lc_per_doc <- lapply(collection[[1]]$doc_sentiment, function(x) mean(abs(x)))
abs_means_bc_per_doc <- lapply(collection[[2]]$doc_sentiment, function(x) mean(abs(x)))
mean(unlist(abs_means_lc_per_doc))
mean(unlist(abs_means_bc_per_doc))
## significance test
data_m3 <- rbind(tibble(sentiment = unlist(abs_means_lc_per_doc), corpus = 'lc'),
tibble(sentiment = unlist(abs_means_bc_per_doc), corpus = 'bc'))
m3 <- lm(sentiment ~ corpus, data = data_m3)
emmeans(m3, specs = pairwise ~ corpus)
## means overall
mList_lc <- unlist(collection[[1]]$doc_sentiment)
mean(abs(mList_lc))
mList_bc <- unlist(collection[[2]]$doc_sentiment)
mean(abs(mList_bc))
## significance test
data_m4 <- rbind(tibble(sentiment = abs(mList_lc), corpus = 'lc'),
tibble(sentiment = abs(mList_bc), corpus = 'bc'))
m4 <- lm(sentiment ~ corpus, data = data_m4)
emmeans(m4, specs = pairwise ~ corpus)
